{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MqGrBR6fph1"
   },
   "source": [
    "## **0. Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uuQ-xRrkoV3",
    "outputId": "c5264f8d-9d0f-4ac2-c885-e00319f02aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zemberek-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/4f/e006418720e5764a302fd4cc048d8b3003bc80cc2317cdc62254fce3abe6/zemberek_python-0.1.2-py3-none-any.whl (93.6MB)\n",
      "\u001b[K     |████████████████████████████████| 93.6MB 98kB/s \n",
      "\u001b[?25hCollecting antlr4-python3-runtime>=4.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/9c/d5ef93dc1e5a862cae004a64d15425c2a1ae8ba967a08f03dfb11aedf7bf/antlr4-python3-runtime-4.9.2.tar.gz (117kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 40.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from zemberek-python) (1.19.5)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.2-cp37-none-any.whl size=144568 sha256=acf7c42425f54144de38c7a7733adab10f4c81406e41af2af1ffd63a07fd3ed7\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/64/ac/8c89516f9cc7341328d7e4a896d2166514798ee24b753f0ca3\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
      "Successfully installed antlr4-python3-runtime-4.9.2 zemberek-python-0.1.2\n"
     ]
    }
   ],
   "source": [
    "pip install zemberek-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9IKNeoivZwxx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\suuser\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string as str\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quPZWI5Wfo3j"
   },
   "source": [
    "## **1. Load DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Um10K4OUasGJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Users\\suuser\\Desktop\\Cesitli\\SICSS\\data\\df_6.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdSADMJ1f0ir"
   },
   "source": [
    "## **2. Define Media Channels' Usernames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "UHY4SG33cLft"
   },
   "outputs": [],
   "source": [
    "media_channels = [\"TurkishIndy\", \"Irna_Turkish\", \"aawsat_turkce\", \"XHTurkey\", \"AlMonitorTurkce\", \"RudawTurkce\",\n",
    "                 \"CRI_Turkish\", \"sputnik_TR\", \"euronews_tr\", \"AJTurk\", \"dw_turkce\", \"bbcturkce\", \"VOATurkish\",\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "jRDd4mICi8KD"
   },
   "outputs": [],
   "source": [
    "tr_media_channels = [\"Ahaber\", \"trthaber\", \"anadoluajansi\", \"trthaber\", \"cnnturk\", \"ihacomtr\", \"dhainternet\", \"Sabah\",\n",
    "                     \"Hurriyet\", \"milliyet\", \"gazetesozcu\", \"cumhuriyetgzt\", \"halktvcomtr\", \"FOXhaber\", \"BirGun_Gazetesi\",\n",
    "                     \"Haberturk\", \"ntv\", \"haber7\", \"Stargazete\", \"yenisafak\", \"turkiyegazetesi\", \"takvim\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM7Cxd_3f82X"
   },
   "source": [
    "## **3. Preprocess Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z80z7qgygCT3"
   },
   "source": [
    "### **3.1. Remove Emojis From Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "nddlSyDMfRak"
   },
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oejkZo7SlA5j"
   },
   "source": [
    "### **3.2. Tokenize & Clean the Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "WVPS9pfMj929"
   },
   "outputs": [],
   "source": [
    "zemberek_tokenizer = TurkishTokenizer.DEFAULT\n",
    "\n",
    "def text_preprocess(text):\n",
    "    allowed_types = ['WordWithSymbol', 'Word', 'Punctuation']\n",
    "    \n",
    "    text = deEmojify(text)\n",
    "    text = \" \".join([token.content for token in zemberek_tokenizer.tokenize(text) if token.type_.name in allowed_types])\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = [word for word in text.split()]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-__zShOgH5f"
   },
   "source": [
    "### **3.2. Tag Each Document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "cwV5Fx7kbKWK"
   },
   "outputs": [],
   "source": [
    "tagged_documents = list()\n",
    "for index, row in df.iterrows():\n",
    "  if row.user_username in media_channels:\n",
    "    tagged_documents.append(TaggedDocument(text_preprocess(row.text.lower()), [row.user_username]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkgr0OgClKeB"
   },
   "source": [
    "## **4. Create a Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cWaageOgQ49"
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(tagged_documents, vector_size=20, min_count=3, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6hKi00XL5Vv"
   },
   "source": [
    "## **5. Network Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "XKyYgm2Po7DP"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "to_observe = list()\n",
    "\n",
    "for index_1 in range(0, len(model.docvecs.index2entity)):\n",
    "    for index_2 in range(0, len(model.docvecs.index2entity)):\n",
    "        if index_1 != index_2:\n",
    "            weight = 1 / (np.linalg.norm(model.docvecs.vectors_docs[index_1]-model.docvecs.vectors_docs[index_2]))\n",
    "            if weight*10 > 0.5:\n",
    "                G.add_edge(model.docvecs.index2entity[index_1], model.docvecs.index2entity[index_2], weight=weight*10)\n",
    "\n",
    "            to_observe.append((model.docvecs.index2entity[index_1], model.docvecs.index2entity[index_2], weight*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "nQPmiVILpmva"
   },
   "outputs": [],
   "source": [
    "nx.write_gml(G,'/content/news_channels.gml')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vaccine_mediachannels_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
